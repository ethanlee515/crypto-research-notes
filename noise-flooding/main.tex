\documentclass{article}

\include{macros}

\title{Noise Flooding with Discrete Gaussians}
\author{}

\begin{document}

\maketitle

\section{Overview}

We want to bound the distance between two discrete Gaussian in terms of their mean and variance.
Here we give a top-down overview of the proof before diving into the details.
Specifically, we state all the lemma in the analysis and defer their proofs for later.

We begin by defining the building blocks for our main theorem.

\begin{definition}[Discrete Gaussian]
	For any $\mu\in\bbZ$ and $\sigma\in\bbR$, denote $\DG{\mu}{\sigma^2}$ as the discrete Gaussian distribution centered at $\mu$ with variance $\sigma^2$.
	To write down the pdf, for all $x\in\bbZ$ we have
	\begin{equation}
		\Pr\sqparens{\DG{\mu}{\sigma^2}=x}=\frac{1}{C}e^{-\parens{x-\mu}^2/2\sigma^2}
	\end{equation}
	for normalization constant
	\begin{equation}
		C=\sum_{x\in\bbZ} e^{-\parens{x-\mu}^2/2\sigma^2}
	\end{equation}
\end{definition}

\begin{definition}[Kullbackâ€“Leibler divergence]
	Let $\cP$ and $\cQ$ be distributions over integers.
	We define the KL divergence to be
	\begin{equation}
		\KL{\cP}{\cQ} = \sum_{x\in\bbZ}\Pr\sqparens{\cP = x}\cdot
		\ln\parens{\frac{\Pr\sqparens{\cP=x}}{\Pr\sqparens{\cQ=x}}}
	\end{equation}
\end{definition}

We now stating precisely the theorem we want to prove here.

\begin{theorem}
	For all $\mu, \nu\in\bbZ$ and $\sigma\in\bbR$, we have
	\begin{equation}
		\KL{\DG{\mu}{\sigma^2}}{\DG{\nu}{\sigma^2}} = \frac{\parens{\nu - \mu}^2}{2\sigma^2}
	\end{equation}
\end{theorem}

To show this, we use a relation between KL divergence and R\'enyi divergence.
We first define the R\'enyi divergence.
\begin{definition}[R\'enyi divergence]
	Let $\cP$ and $\cQ$ be distributions over integers, and let $\alpha\in\bbR$.
	We define
	\begin{equation}
		\renyi{\cP}{\cQ} = \frac{1}{\alpha - 1}
		\ln\parens{\sum_{x\in\bbZ}
		\parens{\Pr\sqparens{\cP=x}}^\alpha
		\parens{\Pr\sqparens{\cQ=x}}^{1-\alpha}}
	\end{equation}
\end{definition}

We can then write KL divergence in terms of R\'enyi divergence:
\begin{lemma}
	For all $\cP$ and $\cQ$ distributions over integers,
	\begin{equation}
		\KL{\cP}{\cQ} = \lim_{\alpha\rightarrow 1}\renyi{\cP}{\cQ}
	\end{equation}
\end{lemma}

Thus it suffices to show that
\begin{lemma}
	\label{lemma:DG-renyi-bound}
	Let $\cP$ and $\cQ$ be distributions over integers, and let $\alpha, \sigma\in\bbR$. We have
	\begin{equation}
		\renyi{\DG{\mu}{\sigma^2}}{\DG{\nu}{\sigma^2}} \leq \frac{\parens{\nu - \mu}^2}{2\sigma^2} \cdot \alpha
	\end{equation}
\end{lemma}

The proof of \Cref{lemma:DG-renyi-bound} uses the following bound for the $\ell_1$-norm of the shifted discrete Gaussian:
\begin{lemma}
	\label{lemma:norm-shifted-DG}
	For all $\mu\in\bbZ$ and $\sigma\in\bbR$ we have
	\begin{equation}
		\sum_{x\in\bbZ}e^{-\parens{x-\mu}^2 / 2\sigma^2} \leq \sum_{x\in\bbZ}e^{x^2 / 2\sigma^2} 
	\end{equation}
\end{lemma}

The proof of \Cref{lemma:norm-shifted-DG} follows from the Poisson summation formula.
We first define Fourier coefficients.
\begin{definition}
	Let $f:\bbR\rightarrow\bbC$ be a Schwarz function, then we write
	\begin{equation}
		\hat{f}(k)=\int_{-\infty}^{\infty} f(x)e^{-2\pi i k x} dx
	\end{equation}
\end{definition}

Now we state the Poisson summation formula.
\begin{lemma}[Poisson summation]
	\label{lemma:Poisson-summation}
	Let $f:\bbR\rightarrow\bbC$ be a Schwarz function, then we have
	\begin{equation}
		\sum_{n\in\bbZ}f(n)=\sum_{k\in\bbZ}\hat{f}(k)
	\end{equation}
\end{lemma}

As one may expect, the next steps use standard results in real analysis and Fourier analysis.
First we state a sufficient condition for exchanging sums and integrals.
\begin{theorem}
	\label{theorem:exchange-sum-and-integral}
	Let $F_k:\bbR\rightarrow\bbC$ such that $F_k\rightarrow F$ uniformly for some $F$, then we have $\int F_k\rightarrow \int F$.
\end{theorem}
We also need convergence of Fourier series.
There are many different criteria and types of convergence for Fourier series;
here we use the following version.
\begin{theorem}
	\label{theorem:Fourier-converge}
	Let $f$ be continuous and periodic on $[0, 1)$, and
	\begin{equation}
		\sum_{k\in\bbZ}\abs{\hat{f}(k)}<\infty,
	\end{equation}
	then for all $x\in\bbR$,
	\begin{equation}
		f(x)=\sum_{k\in\bbZ}\hat{f}(k)e^{2\pi ikx}
	\end{equation}
\end{theorem}
Finally, the convergence theorem above uses the fact that Fourier series is unique.
\begin{theorem}
	Suppose $f$ is continuous and periodic on $[0, 1)$ and satisfies $\hat{f}(k)=0$ for all $k\in\bbZ$, then $f=0$.
\end{theorem}

\section{Proofs of the lemmas}

We present the proofs in reverse order.
First, the convergence of Fourier series is standard material.
We include here for completeness.

\begin{proof}[Proof of \Cref{theorem:Fourier-converge}]
TODO
\end{proof}

\end{document}
